{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome","text":"<p>This repository contains all of the fundamentals to learn how to use the tools for introductory Systems Administration, which is essential in the process of building software.</p>"},{"location":"Docker/","title":"Docker","text":"<p>Docker is a popular open-source platform used for developing, shipping, and running applications. At its core, Docker is about containers. A container is a lightweight, standalone, executable package that includes everything needed to run a piece of software, including the code, runtime, libraries, and system tools. Containers are isolated from each other and the host system, ensuring consistent operation regardless of where the container is deployed. Now, let's see some terminology and concepts that revolve around this \"container\" thing:</p> <ol> <li> <p>Images: Containers are created from Docker images. An image is a lightweight, standalone, and executable software package that includes everything needed to run a container: code, runtime, system tools, libraries, and settings. Docker images are built from a Dockerfile, which is a script composed of various commands and arguments that define the image.</p> </li> <li> <p>Dockerfile: A Dockerfile is a text document that contains all the commands a user could call on the command line to assemble an image. Using <code>docker build</code> users can create an image from a Dockerfile.</p> </li> <li> <p>Docker Hub and Registries: Docker Hub is a service provided by Docker for finding and sharing container images with your team. Private and public repositories can be used to host container images. Other registries include AWS Elastic Container Registry, Google Container Registry, etc.</p> </li> <li> <p>Portability and Consistency: Docker ensures that an application works seamlessly in any environment. A Docker container runs identically whether on a developer\u2019s laptop, a test server, or in production, which eliminates the \u201cit works on my machine\u201d problem.</p> </li> <li> <p>Microservices Architecture: Docker is conducive to microservices architecture \u2013 a design approach to build a single application as a suite of small services, each running in its own container.</p> </li> <li> <p>Docker Compose: For defining and running multi-container Docker applications. With Compose, you use a YAML file to configure your application\u2019s services, networks, and volumes, and then create and start all the services from your configuration with a single command.</p> </li> <li> <p>Docker Swarm: Docker\u2019s orchestration and cluster management tool. Swarm lets you manage a cluster of Docker hosts and deploy application services to them in a scalable, reliable way.</p> </li> </ol> <p>Docker simplifies the deployment of applications, as it allows them to be bundled with all of their dependencies into a single container. This can greatly reduce conflicts between teams running different software on the same infrastructure.</p>"},{"location":"Docker/#minimal-docker-example-an-hello-world-app-in-python","title":"Minimal docker example: an hello world app in python","text":""},{"location":"Docker/#create-the-python-application","title":"Create the Python Application","text":"<p>First, we'll create a simple Python script. Let's name it <code>app.py</code>.</p> <pre><code># app.py\nprint(\"Hello, World!\")\n</code></pre>"},{"location":"Docker/#create-a-dockerfile","title":"Create a Dockerfile","text":"<p>Next, we'll create a Dockerfile to specify how our Docker image should be built.</p> <pre><code># Dockerfile\nFROM python:3.8-slim\n\n# Copy the Python script into the container at /app\nWORKDIR /app\nCOPY app.py /app\n\n# Run the Python script when the container launches\nCMD [\"python\", \"./app.py\"]\n</code></pre> <p>This Dockerfile performs the following steps: 1. Start from a base image containing Python 3.8 (<code>python:3.8-slim</code>). 2. Set the working directory inside the container to <code>/app</code>. 3. Copy the <code>app.py</code> file from your local directory into <code>/app</code> in the container. 4. Set the command to run the Python script when the container starts.</p>"},{"location":"Docker/#build-the-docker-image","title":"Build the Docker Image","text":"<p>Now, build the Docker image from the Dockerfile. Run this command in the directory containing the Dockerfile and <code>app.py</code>.</p> <pre><code>docker build -t hello-world .\n</code></pre> <p>This command builds the Docker image and tags it (<code>-t</code>) with the name <code>hello-world</code>.</p>"},{"location":"Docker/#run-the-docker-container","title":"Run the Docker Container","text":"<p>Finally, run a container based on the image you just built:</p> <pre><code>docker run hello-world\n</code></pre> <p>This command creates and starts a container from the <code>hello-world</code> image. You should see the output <code>Hello, World!</code> in your terminal, which demonstrates that the Python script is executed inside the container.</p> <p>That's it! This is a minimal example to demonstrate the basic workflow of Docker: writing a simple application, creating a Dockerfile, building an image, and running a container from that image.</p>"},{"location":"Docker/#using-docker-with-something-like-numpy","title":"Using docker with something like \"numpy\"","text":""},{"location":"Docker/#create-the-python-application_1","title":"Create the Python Application","text":"<p>First, let's modify our <code>app.py</code> to use <code>numpy</code>.</p> <pre><code># app.py\nimport numpy as np\n\nprint(\"Hello, World! Here's a random number from NumPy:\", np.random.rand())\n</code></pre>"},{"location":"Docker/#create-a-dockerfile_1","title":"Create a Dockerfile","text":"<p>Now, we'll update our Dockerfile to set up a virtual environment and install <code>numpy</code>.</p> <pre><code># Dockerfile\nFROM python:3.8-slim\n\n# Set the working directory in the container\nWORKDIR /app\n\n# Copy the Python script and requirements file into the container\nCOPY app.py /app\nCOPY requirements.txt /app\n\n# Set up a virtual environment\nRUN python -m venv venv\nENV PATH=\"/app/venv/bin:$PATH\"\n\n# Install numpy\nRUN pip install numpy\n\n# Run the Python script when the container launches\nCMD [\"python\", \"./app.py\"]\n</code></pre> <p>In this Dockerfile: 1. We set the working directory to <code>/app</code>. 2. We copy <code>app.py</code> and a <code>requirements.txt</code> file into <code>/app</code> in the container. 3. We create a Python virtual environment inside the container. 4. We activate the virtual environment and install <code>numpy</code>.</p>"},{"location":"Docker/#create-a-requirements-file","title":"Create a Requirements File","text":"<p>Create a <code>requirements.txt</code> file specifying <code>numpy</code> and its version.</p> <pre><code>numpy==1.21.0\n</code></pre>"},{"location":"Docker/#build-the-docker-image_1","title":"Build the Docker Image","text":"<p>Build the Docker image using the updated Dockerfile.</p> <pre><code>docker build -t hello-world-numpy .\n</code></pre>"},{"location":"Docker/#run-the-docker-container_1","title":"Run the Docker Container","text":"<p>Finally, run the container based on the new image.</p> <pre><code>docker run hello-world-numpy\n</code></pre> <p>This command will output a greeting message along with a random number generated by NumPy, demonstrating that NumPy is installed and working inside the container's virtual environment.</p> <p>This example shows how to include a Python virtual environment and specific dependencies (like <code>numpy</code>) in a Docker container, which is a common practice for Python development to ensure consistent and isolated environments.</p>"},{"location":"Docker/#uploading-a-docker-image-to-docker-hub","title":"Uploading a Docker Image to Docker Hub","text":""},{"location":"Docker/#create-a-docker-hub-account","title":"Create a Docker Hub Account","text":"<p>If you don't already have a Docker Hub account, you'll need to create one. Go to Docker Hub and sign up for a free account.</p>"},{"location":"Docker/#log-in-to-docker-hub-from-the-command-line","title":"Log in to Docker Hub from the Command Line","text":"<p>Once you have your Docker Hub account, you need to log in from your command line. Open your terminal and use the following command:</p> <pre><code>docker login\n</code></pre> <p>You'll be prompted to enter your Docker Hub username and password. Once logged in, you can start pushing images to your Docker Hub repository.</p>"},{"location":"Docker/#tag-your-docker-image","title":"Tag Your Docker Image","text":"<p>Before you can upload your image to Docker Hub, you need to tag it with your Docker Hub username and the repository name you want to use. The general format for the tag is:</p> <pre><code>docker tag local-image:tag username/repository:tag\n</code></pre> <p>For example, if your Docker Hub username is <code>username</code> and you want to name your repository <code>hello-world-numpy</code>, and you're using the <code>latest</code> tag, the command would be:</p> <pre><code>docker tag hello-world-numpy:latest username/hello-world-numpy:latest\n</code></pre> <p>This command tags the <code>hello-world-numpy</code> image from our previous example.</p>"},{"location":"Docker/#push-the-image-to-docker-hub","title":"Push the Image to Docker Hub","text":"<p>Now, push the tagged image to Docker Hub using the following command:</p> <pre><code>docker push username/repository:tag\n</code></pre> <p>Continuing our example, you would run:</p> <pre><code>docker push username/hello-world-numpy:latest\n</code></pre> <p>This command uploads the <code>hello-world-numpy</code> image to your Docker Hub repository.</p>"},{"location":"Docker/#verify-the-upload","title":"Verify the Upload","text":"<p>After the push operation completes, go to your Docker Hub account and check your repositories. You should see the <code>hello-world-numpy</code> repository listed with the <code>latest</code> tag.</p>"},{"location":"Docker/#note","title":"Note:","text":"<ul> <li>Ensure that your local image name and tag match exactly with the ones you're trying to push to Docker Hub.</li> <li>Remember to replace <code>username</code>, <code>repository</code>, and <code>tag</code> with your actual Docker Hub username, desired repository name, and tag.</li> <li>If you want your repository to be private, you need to set it as private on Docker Hub. By default, repositories are public.</li> </ul>"},{"location":"Git/","title":"Git","text":"<pre><code>to add : https://stackoverflow.com/questions/37937984/git-refusing-to-merge-unrelated-histories-on-rebase\nTODOs: Git worktree, git bare repository, git submodules\n</code></pre>"},{"location":"Git/#git-basic-configuration","title":"git basic configuration","text":"<p>When you install git for the first time on the new machine. Set the default command line editor as vim.</p> <pre><code>    git config --global core.editor vim\n    git config --global user.name \"John Doe\"\n    git config --global user.email \"john@doe.net\"\n    git config --global color.ui \"auto\"\n</code></pre> <p>To list all of the configs:</p> <pre><code>    git config --list\n</code></pre>"},{"location":"Git/#git-starter","title":"git starter","text":"<p>To start a new git project on github:</p> <pre><code>    git init\n    add .gitignore # for the files you don't want to commit\n    git remote add 'name of the remote' www.github.com/angelobattaglia/progetto\n    git remote set-url 'name of the remote' git@github.com:angelobattaglia/progetto.git\n    git add -A or git add .\n    git commit -a (-m \"first commit\")\n    git push 'name of the remote' master\n</code></pre> <p>If you want remove some file that you added to the .gitignore later:</p> <pre><code>    git rm --cached filetoremovefromthecache\n</code></pre> <p>If you want to show all of the graph of commits just type:</p> <pre><code>    git log --all --graph --decorate (--oneline)\n</code></pre> <p>Updating local repository from remote. Let's say your local branch is out of date, and you need to fetch changes from the same branch but from remote. In order to do this, we need to fetch from remote and then merge our local branch with the remote branch. So a git pull is a shortcut to  perform a git fetch followed up by a git merge.</p> <pre><code>    git pull\n</code></pre>"},{"location":"Git/#working-with-remote","title":"Working with Remote","text":"<p>To see how many remote for a git repository:</p> <pre><code>    git remote -v\n</code></pre> <p>To add a remote to a git repository with https:</p> <pre><code>    git remote add \"Remote 1\" www.github.com/angelo/progetto\n    git remote add \"Remote 2\" www.gitlab.com/angelo/progetto\n</code></pre> <p>To remove a remote of an already initialized git repository:</p> <pre><code>    git remote remove \"Remote 1\"\n    git remote remove \"Remote 2\"\n</code></pre> <p>Push to remote(s):</p> <pre><code>    git push \"remote name\" \"branch name\"\n    git push all\n</code></pre>"},{"location":"Git/#branching","title":"Branching","text":"<p>Listing branches:</p> <p>List all the branches of a given project</p> <pre><code>    git branch -a\n</code></pre> <pre><code>    git branch -r   # list remote branches\n</code></pre> <pre><code>    git branch      # list local branches\n</code></pre> <p>To change from the current branch, for example, to another one use the argument \"checkout\":</p> <pre><code>    git checkout 'branchname'\n</code></pre> <p>Local branches: colored white. Remote branches: colored red \"remotes/origin\" If you want to abort all current changes that aren't committed:</p> <pre><code>    git reset --hard\n</code></pre> <p>If you just want to restore one file:</p> <pre><code>    git checkout filetorestore.txt\n</code></pre> <p>Branch pointed as \"HEAD\" is the latest committed among all the branches</p>"},{"location":"Git/#git-checkout-moving-between-branches-in-git","title":"Git Checkout (moving between branches in git)","text":"<p>The easiest way to switch branch on Git is to use the \u201cgit checkout\u201d command and specify the name of the branch you want to switch to.  If the destination branch does not exist, you have to append the \u201c-b\u201d option,  otherwise you won\u2019t be able to switch to that branch.</p> <pre><code>git checkout &lt;existing_branch&gt;\n</code></pre>"},{"location":"Git/#how-to-merge","title":"How to merge","text":"<p>Merging in Git, especially when working with GitHub, is a common task that integrates changes from one branch into another. Here's a comprehensive guide on how to merge changes using Git with GitHub, and subsequently update your local repository to reflect these changes.</p>"},{"location":"Git/#merging-in-github","title":"Merging in GitHub","text":"<ol> <li> <p>Open a Pull Request (PR): A Pull Request in GitHub is essentially a request to merge one branch into another. Navigate to the repository where you're contributing, and click on \"Pull Requests\" &gt; \"New pull request\". Choose the base branch that you want to merge into and the compare branch that you want to merge from.</p> </li> <li> <p>Review the Changes: Before merging, it's a good practice to review the changes. GitHub provides a diff view that shows the added, modified, or removed lines.</p> </li> <li> <p>Resolve Conflicts (if any): If there are any conflicts, GitHub will alert you. You must resolve these conflicts before proceeding. This can often be done directly in the GitHub interface or by checking out the branch locally and resolving the conflicts manually.</p> </li> <li> <p>Merge the Pull Request: Once any conflicts are resolved and you're ready to integrate the changes, click the \"Merge pull request\" button. Optionally, you can add a merge commit message to document the merge.</p> </li> </ol>"},{"location":"Git/#updating-your-local-repository-after-merging","title":"Updating Your Local Repository After Merging","text":"<p>After merging changes on GitHub, you'll want to update your local repository to reflect the merged state of the remote repository.</p> <ol> <li> <p>Switch to the Relevant Branch: Make sure you're on the branch into which you merged the changes. You can switch branches with the <code>git checkout</code> command.    <code>bash    git checkout main</code>    Replace <code>main</code> with the name of the branch you merged the changes into.</p> </li> <li> <p>Fetch the Latest Changes: Fetch the changes from the remote repository without merging them into your local repository.    <code>bash    git fetch origin</code> <code>origin</code> is the default name for the remote repository. If you've named it differently, replace <code>origin</code> with the name you've given.</p> </li> <li> <p>Merge the Changes: Now, merge the fetched changes into your local branch.    <code>bash    git merge origin/main</code>    Replace <code>main</code> with the name of your branch. This command merges the remote changes into your current branch, synchronizing it with the remote repository.</p> </li> <li> <p>Push Local Changes (if any): If you've made any local changes that need to be synchronized with the remote repository, push them using:    <code>bash    git push origin main</code>    Again, replace <code>main</code> with the appropriate branch name.</p> </li> </ol>"},{"location":"Git/#best-practices","title":"Best Practices","text":"<ul> <li>Regularly Pull Changes: To minimize merge conflicts, regularly pull changes from the remote repository to your local branches, especially before starting new work.</li> <li>Use Feature Branches: When working on new features or fixes, create separate branches for each task. This makes managing and merging changes easier.</li> <li>Communicate with Your Team: If you're working in a team, communicate about branch merges to avoid conflicts and duplicative work.</li> </ul> <p>Merging and updating your repository in Git can initially seem complex, but with practice, it becomes a routine part of managing code changes. By following these steps and best practices, you'll ensure that your project remains current and organized.</p> <p>If you've merged changes on GitHub and your local repository isn't up to date with those changes, you can update your local repository by pulling the changes from GitHub. This process involves fetching the changes made on the remote and merging them into your local branch. Here's how you can do it:</p> <ol> <li> <p>Open your terminal or command prompt.</p> </li> <li> <p>Navigate to your local repository's directory:    Use the <code>cd</code> command to change directories to your local repository if you're not already there.    <code>bash    cd /path/to/your/repository</code></p> </li> <li> <p>Switch to the branch you want to update:    Ensure you're on the correct branch that you wish to update with the changes from GitHub. Typically, this is the main branch or the branch into which you've merged changes on GitHub.    <code>bash    git checkout main</code>    Replace <code>main</code> with the name of the branch you're updating if it's different.</p> </li> <li> <p>Pull the changes from GitHub:    Use the <code>git pull</code> command to fetch the changes from the remote repository and merge them into your local branch.    <code>bash    git pull origin main</code>    This command tells Git to fetch the changes from the <code>main</code> branch of the remote repository named <code>origin</code> and then merge those changes into your current branch. Again, replace <code>main</code> with your branch name if it's different.</p> </li> </ol> <p>The <code>git pull</code> command is essentially a combination of <code>git fetch</code> followed by <code>git merge</code>, where Git first fetches the changes from the specified remote branch and then merges those changes into the current branch of your local repository. This updates your local repository to reflect the state of the repository on GitHub.</p> <p>If you encounter any merge conflicts during this process, Git will alert you and ask you to resolve them. You'll need to manually edit the files with conflicts, choose which changes to keep, and then commit those resolutions before proceeding.</p> <p>Following these steps ensures that your local repository is synchronized with the changes made on GitHub, keeping your project files up to date.</p> <p>You can merge one or more branches. In the current branch, run:</p> <pre><code>    git merge \"branch-one\"\n    git merge \"branch-one\" \"branch-two\"\n</code></pre>"},{"location":"Git/#how-to-update-your-local-repository-after-merges-made-on-github","title":"How to update your local repository after merges made on GitHub","text":"<p>If you've merged changes on GitHub and your local repository isn't up to date with those changes, you can update your local repository by pulling the changes from GitHub. This process involves fetching the changes made on the remote and merging them into your local branch. Here's how you can do it:</p> <ol> <li> <p>Open your terminal or command prompt.</p> </li> <li> <p>Navigate to your local repository's directory: Use the <code>cd</code> command to change directories to your local repository if you're not already there.</p> </li> </ol> <pre><code>cd /path/to/your/repository\n</code></pre> <ol> <li>Switch to the branch you want to update: Ensure you're on the correct branch that you wish to update with the changes from GitHub. Typically, this is the main branch or the branch into which you've merged changes on GitHub.</li> </ol> <pre><code>git checkout main\n</code></pre> <p>Replace <code>main</code> with the name of the branch you're updating if it's different.</p> <ol> <li>Pull the changes from GitHub: Use the <code>git pull</code> command to fetch the changes from the remote repository and merge them into your local branch.</li> </ol> <pre><code>git pull origin main\n</code></pre> <p>This command tells Git to fetch the changes from the <code>main</code> branch of the remote repository named <code>origin</code> and then merge those changes into your current branch. Again, replace <code>main</code> with your branch name if it's different.</p> <p>The <code>git pull</code> command is essentially a combination of <code>git fetch</code> followed by <code>git merge</code>, where Git first fetches the changes from the specified remote branch and then merges those changes into the current branch of your local repository. This updates your local repository to reflect the state of the repository on GitHub.</p> <p>If you encounter any merge conflicts during this process, Git will alert you and ask you to resolve them. You'll need to manually edit the files with conflicts, choose which changes to keep, and then commit those resolutions before proceeding.</p> <p>Following these steps ensures that your local repository is synchronized with the changes made on GitHub, keeping your project files up to date.</p>"},{"location":"Git/#how-to-make-a-pull-request-on-github","title":"How to make a pull request on GitHub","text":"<ul> <li>Find a project you want to contribute to</li> <li>Fork it</li> <li>Clone it to your local system</li> <li>Create a new branch</li> <li>Write your changes</li> <li>Push it back to your repo</li> <li>Click the Compare &amp; pull request button</li> <li>Click Create pull request to open a new pull request</li> </ul>"},{"location":"Git/#tagging-a-particular-commit","title":"Tagging a particular commit","text":"<pre><code>    git tag \"tag name\" # Will tag the commit HEAD (the latest) if not specified otherwise\n    git tag \"hash of the commit\" \"tag name\" # Will tag the specific commit tagged with that hash\n</code></pre> <p>List all the tags:</p> <pre><code>    git tag\n</code></pre>"},{"location":"Git/#reset-and-rebase","title":"Reset and Rebase","text":"<p>To delete a commit with a typo in the commit message on your GitHub project, you can follow these steps:</p>"},{"location":"Git/#step-1-identify-the-commit","title":"Step 1: Identify the Commit","text":"<p>First, determine the hash (SHA-1) of the commit you want to delete. You can use <code>git log</code> to see the commit history and identify the offending commit.</p> <pre><code>git log\n</code></pre>"},{"location":"Git/#step-2-revert-to-the-previous-commit","title":"Step 2: Revert to the Previous Commit","text":"<p>If the mistaken commit is the latest one, you can reset your branch to the previous commit. If it's not the latest commit, you can use an interactive rebase to modify your commit history.</p>"},{"location":"Git/#if-the-mistaken-commit-is-the-latest","title":"If the mistaken commit is the latest:","text":"<ol> <li>Use <code>git reset</code> to revert to the previous commit:</li> </ol> <pre><code>git reset --hard HEAD~1\n</code></pre> <ol> <li>Force-push the changes to your remote repository:</li> </ol> <pre><code>git push origin +HEAD\n</code></pre>"},{"location":"Git/#step-3-interactive-rebase-if-the-commit-is-not-the-latest","title":"Step 3: Interactive Rebase (if the commit is not the latest)","text":"<p>If the commit is not the latest one, you can use an interactive rebase to remove or edit the commit.</p> <ol> <li>Start an interactive rebase from a point before the mistaken commit:</li> </ol> <pre><code>git rebase -i HEAD~n\n</code></pre> <p>Replace <code>n</code> with the number of commits back you want to rebase, which should include the mistaken commit.</p> <ol> <li> <p>In the interactive rebase editor, you will see a list of commits. Find the line with the mistaken commit message. You can either remove that line to delete the commit or change the word <code>pick</code> to <code>edit</code> to modify the commit.</p> </li> <li> <p>If you chose to edit the commit, after closing the editor, you can change the commit message:</p> </li> </ol> <pre><code>git commit --amend\n</code></pre> <ol> <li>Continue the rebase process:</li> </ol> <pre><code>git rebase --continue\n</code></pre> <ol> <li>Finally, force-push the changes to your remote repository:</li> </ol> <pre><code>git push origin +HEAD\n</code></pre>"},{"location":"Git/#step-4-verify","title":"Step 4: Verify","text":"<p>Ensure your repository's commit history looks correct:</p> <pre><code>git log\n</code></pre> <p>This should remove the commit with the typo from your project's history on GitHub. Remember, force-pushing changes the commit history and can affect other collaborators' work, so proceed with caution and communicate with your team if necessary.</p> <p>Sure, let's go over Step 3 in more detail. This step involves using interactive rebase to modify your commit history, which is particularly useful if the mistaken commit is not the latest one.</p>"},{"location":"Git/#step-3-interactive-rebase","title":"Step 3: Interactive Rebase","text":"<ol> <li>Start Interactive Rebase:</li> </ol> <p>Begin by starting an interactive rebase from a point before the mistaken commit. You need to specify the number of commits back you want to rebase. For example, if you need to go back 3 commits:</p> <p><code>bash    git rebase -i HEAD~3</code></p> <p>This will open an editor with a list of the last 3 commits.</p> <ol> <li>Modify the Commit List:</li> </ol> <p>In the interactive rebase editor, you'll see a list of commits, each preceded by the word <code>pick</code>. It will look something like this:</p> <p><code>pick a1b2c3d Commit message before the mistake    pick b2c3d4e Mistaken commit explaination    pick c3d4e5f Commit message after the mistake</code></p> <p>Find the line with the mistaken commit message. You have two main options here:</p> <ul> <li> <p>Remove the Commit (if you want to delete it): Simply delete the line with the mistaken commit.</p> </li> <li> <p>Edit the Commit Message (if you want to correct it): Change the word <code>pick</code> to <code>edit</code> on the line with the mistaken commit:</p> <p><code>pick a1b2c3d Commit message before the mistake  edit b2c3d4e Mistaken commit explaination  pick c3d4e5f Commit message after the mistake</code></p> </li> <li> <p>Save and Exit the Editor:</p> </li> </ul> <p>Save the changes and exit the editor. The rebase process will pause at the commit you marked for editing.</p> <ol> <li>Edit the Commit:</li> </ol> <p>If you chose to edit the commit, you'll now be prompted to amend the commit. Change the commit message:</p> <p><code>bash    git commit --amend</code></p> <p>This will open an editor where you can correct the commit message. Change \"explaination\" to \"explanation\" and save the changes.</p> <ol> <li>Continue the Rebase:</li> </ol> <p>After amending the commit, continue the rebase process:</p> <p><code>bash    git rebase --continue</code></p> <p>If there are more commits to edit or resolve conflicts, Git will guide you through the process. Otherwise, the rebase will complete.</p> <ol> <li>Force Push the Changes:</li> </ol> <p>Since you've rewritten the commit history, you need to force-push the changes to your remote repository:</p> <p><code>bash    git push origin +HEAD</code></p>"},{"location":"Git/#summary","title":"Summary","text":"<p>In this step, you've used an interactive rebase to either remove or edit a specific commit. This is a powerful way to clean up your commit history, but it should be used carefully, especially when collaborating with others, as it rewrites the commit history.</p>"},{"location":"Links/","title":"Links","text":""},{"location":"Links/#tooling","title":"Tooling","text":"<p>The operating system is a development environment.</p> <ul> <li>Minimal linux-based/FreeBSD/OpenBSD operating system</li> <li>A posix compliant shell (recommended), such as dash. Bash is good as well, albeit not stricly POSIX.</li> <li>C</li> <li>Make</li> <li>Git</li> <li>The UNIX core utilities</li> <li>tmux, mosh, vim, gdb, valgrind</li> </ul>"},{"location":"Links/#books-used","title":"Books used","text":"<ul> <li>The C Programming Language K&amp;R 2nd Edition</li> <li>Understanding and Using C pointers by Richard Reese</li> <li>Pointers on C, 1st Edition, by Kenneth Reek</li> <li>Practical C programming</li> <li>C in a nutshell</li> <li>21st Century C</li> <li>Mastering Algorithms With C</li> <li>Numerical Recipes In C The Art Of ... 2nd edition, W. Press, S. Teukolsky, W. Vetterling, B. Flannery</li> <li>Algorithms + Data Structure = Programs</li> <li>The missing semester</li> </ul>"},{"location":"Links/#helpful-external-resources","title":"Helpful External Resources","text":"<ul> <li>Command line environment</li> <li>Course of Systems Programming by Notre Dame University</li> <li>Great practical ideas in Computer Science by CMU</li> <li>The UNIX philosophy</li> <li>The FreeBSD manual</li> <li>The Gentoo Handbook</li> <li>The Archwiki</li> <li>THE Ultimate Book List</li> <li>Programming Concepts to know</li> <li>Teach yourself CS</li> <li>MATLAB examples</li> <li>Diagrams of all sorts (ER, flowchart, UML)</li> <li>Minimalist graphics library</li> <li>Thinkpad wiki</li> <li>CLI design guidelines</li> </ul>"},{"location":"Links/#the-unix-command-line-shell-scripting","title":"The UNIX command line (shell scripting)","text":"<ul> <li>Pure Shell Bible by Dylan Araps</li> <li>commandlinefu</li> <li>learning the shell</li> <li>Shell commands explained</li> <li>Terminals are sexy</li> <li>Various Linux tutorials</li> <li>cheat sheet shell</li> </ul>"},{"location":"Links/#practice-regular-expressions","title":"Practice Regular Expressions","text":"<ul> <li>RegexGolf</li> <li>Regexone</li> <li>Regex101</li> </ul>"},{"location":"Links/#latex-and-markdown","title":"Latex and Markdown","text":"<ul> <li>Free latex editor (although worse than the Make and Vi approach)</li> <li>Latex web editor</li> <li>Latex tutorial</li> <li>Markdown tutorial</li> <li>Handwritten formula classification to Latex</li> <li>Math Editor for Latex</li> <li>Latex AMS</li> <li>Latex AMS: short guide</li> </ul>"},{"location":"Links/#make","title":"Make","text":"<ul> <li>Makefile tutorial</li> <li>GNU Make documentation</li> <li>make</li> <li>Generic C Project template</li> <li>Simple Project Structure in C</li> <li>Simple Project Structure in Cpp</li> </ul>"},{"location":"Links/#git-and-mercurial","title":"Git and Mercurial","text":"<ul> <li>Mercurial short guide</li> <li>Git learning material</li> <li>Interactive Git learning</li> <li>Progit book</li> </ul>"},{"location":"Links/#competitive-programming","title":"Competitive Programming","text":"<ul> <li>Learn C++</li> <li>C++ book list</li> <li>FANG interview questions</li> <li>Competitive Programmer's handbook</li> <li>Nice quora question</li> <li>Competitive programming algorithms (cp-algorithms.com)</li> <li>Programming Challenges, Skiena</li> <li>National University of Singapore book on Competitive Programming </li> <li>Practice: cses.fi</li> <li>Practice: codewars.com</li> <li>Practice: adventofcode.com</li> <li>Practice: Codeforces</li> <li>Practice: Codeforces ladder</li> <li>Practice: Project Euler</li> <li>Practice: AtCoder</li> </ul>"},{"location":"Links/#project-based-learning","title":"Project based learning","text":"<ul> <li>From the Transistor by George Hotz</li> <li>Aggregator of project tutorials</li> <li>Projects list for beginners</li> <li>Projects from Scratch</li> <li>Build your own X</li> <li>Shell</li> <li>Text Editor</li> <li>Interpreter</li> <li>Compiler</li> <li>Compiler 2</li> <li>Build System</li> <li>Database</li> <li>Building a Web Browser</li> <li>Physically based rendering book (Computer Graphics)</li> <li>Emacs</li> <li>SQLbolt</li> </ul>"},{"location":"Links/#where-to-find-software","title":"Where to find software","text":"<ul> <li>Text Editors</li> <li>Suckless recommandations</li> <li>Good software according to cat-v.org</li> <li>Alternatives list</li> <li>Other list of recommandations</li> <li>Linux ricing guide</li> <li>Uses This</li> <li>Modern UNIX utilities</li> <li>\"The Book of Secret Knowledge\"</li> </ul>"},{"location":"Links/#java","title":"Java","text":"<ul> <li>Which Open JDK distribution to pick up?</li> <li>Recommended JDK distribution: Amazon Corretto 8</li> <li>Maven Documentation</li> <li>Quick Maven Tutorial</li> <li>Java 8 standard API documentation</li> <li>Java 8 tutorial</li> </ul>"},{"location":"Links/#licencing-software","title":"Licencing Software","text":"<ul> <li>Licencing a repository: GitHub</li> <li>Opensource licencing</li> <li>Choose a Licence</li> </ul>"},{"location":"Make/","title":"Make","text":"<p>The mechanics of programming usually follow a fairly simple routine of editing source files, compiling the source into an executable form, and debugging the result. The make program is intended to automate the mundane aspects of transforming source code into an executable. The advantages of make over scripts is that you can specify the relationships between the elements of your program to make, and it knows through these relationships and timestamps exactly what steps need to be redone to produce the desired program each time. Using this information, make can also optimize the build process avoiding unnecessary steps.  O'Reilly Managing Projects with GNU Make, Third Edition By Robert Mecklenburg November 2004</p>"},{"location":"Make/#use-cases","title":"Use cases","text":""},{"location":"Make/#the-best-latex-writing-system-imho","title":"The best Latex writing system (IMHO)","text":"<p>Creating a modular LaTeX document and building it with a Makefile is the best way to streamline the document creation process and enhance maintainability, in my opinion.  This approach is particularly useful for large documents, such as academic papers, theses, or books, where different sections or chapters can be worked on independently. It's also useful to provide a document that is reproducible from source, especially when letting the community on git-based websites the opportunity to contribute to it.</p>"},{"location":"Make/#1-structuring-a-modular-latex-document","title":"1. Structuring a Modular LaTeX Document","text":"<p>A modular LaTeX document is one where different components of the document (e.g., chapters, sections, or custom commands) are contained in separate files.  This makes the document easier to manage, especially for collaborative projects. Here\u2019s how you might structure it:</p> <ul> <li>Main File: The main LaTeX file that includes the document class, preamble (with packages, custom commands, etc.), and input commands to include other files.</li> <li>Section Files: Separate <code>.tex</code> files for different sections or chapters of the document.</li> <li>Resources: Other directories may include figures, tables, or additional resources.</li> </ul> <p>An example structure could look like this:</p> <pre><code>main.tex\nsections/\n  - introduction.tex\n  - chapter1.tex\n  - chapter2.tex\n  - conclusion.tex\nfigures/\n  - figure1.png\n  - figure2.png\nMakefile\n</code></pre> <p>In <code>main.tex</code>, you would use <code>\\input{sections/introduction}</code> to include the <code>introduction.tex</code> file, and so on for the other sections. This approach keeps your main file clean and focuses only on the document structure.</p>"},{"location":"Make/#2-writing-a-makefile-for-latex","title":"2. Writing a Makefile for LaTeX","text":"<p>A Makefile automates the compilation of your LaTeX document, handling the build process with simple commands. LaTeX documents often need multiple compilation passes to correctly generate tables of contents, lists of figures, and to resolve cross-references.</p> <p>Here's a simple Makefile template for a LaTeX project:</p> <pre><code># Makefile for compiling LaTeX documents\n\n# Name of the main LaTeX file without the extension\nMAIN = main\n\n# Default target\nall: pdf\n\n# Compile PDF\npdf:\n    pdflatex $(MAIN)\n    bibtex $(MAIN) || true # Run bibtex, ignore errors if no bibliography\n    pdflatex $(MAIN)\n    pdflatex $(MAIN)\n\n# Clean auxiliary files\nclean:\n    rm -f *.aux *.bbl *.blg *.log *.toc *.out\n\n# Clean all generated files\ndistclean: clean\n    rm -f $(MAIN).pdf\n</code></pre> <p>This Makefile defines several targets:</p> <ul> <li><code>all</code>: The default target, which just redirects to the <code>pdf</code> target.</li> <li><code>pdf</code>: Compiles the LaTeX document into a PDF, running <code>pdflatex</code> and <code>bibtex</code> as needed. It runs <code>pdflatex</code> multiple times to ensure all references are updated.</li> <li><code>clean</code>: Removes auxiliary files generated by LaTeX.</li> <li><code>distclean</code>: Removes all generated files, including the final PDF.</li> </ul> <p>To use this Makefile, you would run:</p> <ul> <li><code>make</code> or <code>make all</code> to compile the document into a PDF.</li> <li><code>make clean</code> to remove auxiliary files.</li> <li><code>make distclean</code> to remove all generated files, including the PDF.</li> </ul> <p>This setup allows for a clean and efficient workflow for managing and compiling modular LaTeX documents, particularly suitable for complex or large-scale projects.</p>"},{"location":"MkDocs/","title":"MkDocs","text":"<p>For full documentation visit mkdocs.org. Look out for: mkdocs material.</p>"},{"location":"MkDocs/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"MkDocs/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"SSH_GPG/","title":"SSH and GPG","text":"<p>SSH is a protocol that used to connect to servers. GPG (gnu privacy guard) is an open source implementation of PGP.</p>"},{"location":"SSH_GPG/#ssh","title":"SSH","text":""},{"location":"SSH_GPG/#key-generation","title":"Key generation","text":"<p>In order to provide a public key, each user in your system must generate one. You should check to make sure you don\u2019t already have a key. By default, a user\u2019s SSH keys are stored in that user\u2019s ~/.ssh directory. You\u2019re looking for a pair of files named something like id_dsa or id_rsa and a matching file with a .pub extension. The .pub file is your public key, and the other file is your private key. If you don't have these, go to the $HOME dir and:</p> <pre><code>cd $HOME/.ssh\nls\nssh-keygen\n</code></pre> <p>It will ask you for a location with a name. You choose $(HOME)/.ssh/id_rsa. Click return 2 times.</p> <pre><code>ls\nid_rsa id_rsa.pub\n</code></pre> <p>So: id_rsa -&gt; private key, id_rsa.pub -&gt; public key. Never ever share the private key. When on Windows, use git bash. On a UNIX sys do this:</p> <pre><code>ssh -T git@github.com\n</code></pre> <p>Say yes, and then try to download a repo with SSH. If you have problems:</p> <ul> <li> <p>Testing your SSH connection</p> </li> <li> <p>Generating Multiple keys for different remote servers to connect to</p> </li> </ul>"},{"location":"SSH_GPG/#multiple-ssh-keys-for-different-servers","title":"Multiple SSH keys for different servers","text":"<p>You have 3 accounts in 3 hosting services. You need a key for each of those. This Method works also for n accounts. This guide is being taylored for Windows-based operating systems.</p>"},{"location":"SSH_GPG/#powershell-as-admin","title":"Powershell as Admin","text":"<p>In Windows PowerShell (run as admin):</p> <ul> <li>Check the current status of ssh-agent:</li> </ul> <pre><code>   Get-Service | ?{$_.Name -like '*ssh-agent*'} | select -Property Name, StartType, Status\n</code></pre> <ul> <li>Enable the Service if it is disabled:</li> </ul> <pre><code>   Set-Service -Name ssh-agent -StartupType Manual\n</code></pre> <ul> <li>Start the Service:</li> </ul> <pre><code>   Start-Service ssh-agent\n</code></pre> <ul> <li>Add your key as before:</li> </ul> <pre><code>   ssh-add &lt;path to the key&gt;\n</code></pre>"},{"location":"SSH_GPG/#create-ssh-keys-for-all-accounts","title":"Create SSH keys for all accounts","text":"<p>First make sure your current directory is your .ssh folder.</p> <pre><code>    cd ~/.ssh\n</code></pre> <p>Syntax for generating unique ssh key for ann account is:</p> <pre><code>     ssh-keygen -t rsa -C \"your-email-address\" -f \"github-username\"\n</code></pre> <p>here,</p> <p>-C stands for comment to help identify your ssh key</p> <p>-f stands for the file name where your ssh key get saved</p>"},{"location":"SSH_GPG/#now-generating-ssh-keys-for-my-two-accounts","title":"Now generating SSH keys for my two accounts","text":"<pre><code>     ssh-keygen -t rsa -C \"first_email@gmail.com\" -f \"github-first-account\"\n     ssh-keygen -t rsa -C \"second_email@gmail.com\" -f \"github-second-personal\"\n</code></pre> <p>Notice here first-account and second-account are the username of my github accounts corresponding to first-account@gmail.com and second-account@gmail.com email ids respectively.</p> <p>After entering the command the terminal will ask for passphrase, leave it empty and proceed.</p>"},{"location":"SSH_GPG/#add-ssh-keys-to-ssh-agent","title":"Add SSH keys to SSH Agent","text":"<p>Now we have the keys but it cannot be used until we add them to the SSH Agent. Note: the \"-k\" flag is lowercase on Windows and uppercase on UNIX shells (As it worked for me).</p> <pre><code>     ssh-add -k ~/.ssh/github-first-account\n     ssh-add -k ~/.ssh/github-second-account\n</code></pre> <p>You can read more about adding keys to SSH Agent here.</p>"},{"location":"SSH_GPG/#add-ssh-public-key-to-the-github","title":"Add SSH public key to the Github","text":"<p>For the next step we need to add our public key (that we have generated in our previous step) and add it to corresponding github accounts.</p> <p>For doing this we need to:</p> <ul> <li>Copy the public key to the clipboard</li> </ul> <p>We can copy the public key by opening the github-rahul-office.pub file in nvim and then copying the content of it.</p> <pre><code>     nvim ~/.ssh/github-first-account.pub\n     nvim ~/.ssh/github-second-account.pub\n</code></pre> <p>And then, paste the public key on Github.</p> <ol> <li> <p>Sign in to Github Account</p> </li> <li> <p>Go to Settings &gt; SSH and GPG keys &gt; New SSH Key</p> </li> <li> <p>Paste your copied public key and give it a Title of your choice.</p> </li> </ol>"},{"location":"SSH_GPG/#create-a-config-file-and-make-host-entries","title":"Create a Config File and Make Host Entries","text":"<p>The ~/.ssh/config file allows us specify many config options for SSH.</p> <p>If config file not already exists then create one (make sure you are in ~/.ssh directory)</p> <pre><code>     touch config\n</code></pre> <p>The commands below opens config in your default editor....Likely TextEdit, VS Code.</p> <pre><code>     open config\n</code></pre> <p>Now we need to add these lines to the file, each block corresponding to each account we created earlier.</p> <pre><code>     #first-account\n     Host github.com-first-account\n          HostName github.com\n          User git\n          IdentityFile ~/.ssh/github-first-account\n\n     #second-account\n     Host github.com-second-account\n          HostName github.com\n          User git\n          IdentityFile ~/.ssh/github-second-account\n</code></pre>"},{"location":"SSH_GPG/#handling-git","title":"Handling Git","text":"<p>From now on, to ensure that our commits and pushes from each repository on the system uses the correct GitHub user \u2014 we will have to configure user.email and user.name in every repository freshly cloned or existing before.</p> <p>To do this use the following commands.</p> <pre><code>     git config user.email \"first-account@gmail.com\"\n     git config user.name \"first-account Name\"\n\n     git config user.email \"second-account@gmail.com\"\n     git config user.name \"second-account Name\"\n</code></pre> <p>Pick the correct pair for your repository accordingly.</p> <p>To push or pull to the correct account we need to add the remote origin to the project</p> <pre><code>     git remote add origin git@github.com-first-account:first-account\n\n     git remote add origin git@github.com-second-account:second-account\n</code></pre> <p>Now you can use:</p> <pre><code>     git push\n\n     git pull\n</code></pre>"},{"location":"SSH_GPG/#references","title":"References","text":"<ul> <li>(1)</li> <li>(2)</li> </ul>"},{"location":"SSH_GPG/#gpg-gnu-privacy-guard","title":"GPG (GNU privacy guard)","text":"<p>First off, we need to generate a key pair. A key pair is composed by a private key and a public key.</p> <pre><code>gpg --full-gen-key\n</code></pre> <p>It will generate a file, usually, in the $(HOME)/.gnupg directory.</p>"},{"location":"Compilation%20Process/Basics/","title":"Basics","text":""},{"location":"Compilation%20Process/Basics/#references","title":"References","text":"<ul> <li>Inlcude guard (wikipedia link)</li> <li>Systems Programming in UNIX Linux by K.C. Wang, Springer</li> <li>Driving Compilers</li> </ul>"},{"location":"Compilation%20Process/Basics/#lets-take-two-files-to-start-with","title":"Let's take two files to start with","text":"<pre><code>gcc Script01.c Script02.c\n</code></pre> <pre><code>gcc Script01.c Script02.c\n</code></pre>"},{"location":"Compilation%20Process/Basics/#simple-convert-into-a-binary-executable","title":"Simple convert into a binary executable","text":"<pre><code>gcc Script01.c Script02.c\n</code></pre> <p>or ..</p> <pre><code>tcc Script01.c Script02.c\n</code></pre>"},{"location":"Compilation%20Process/Basics/#statically-linked-library","title":"Statically linked library","text":"<ul> <li>First step: compile Script02.c into Script02.o, important using the '-c' flag</li> </ul> <pre><code>gcc -c Script02.c\n</code></pre> <ul> <li>Second step: create a Statically Linked Library with Script02.o as a member of it</li> </ul> <pre><code>ar rcs libmylib.a Script02.o\n</code></pre> <ul> <li>Third step: Static compile-link Script01.c with libmylib.a as a linked library</li> <li>'-static' specifies that is being statically linked</li> <li>'-L.' specifies the library path (current directory .)</li> <li>'-l' specifies the library</li> <li>'mylib' is specified without the prefex lib, as well as the suffix .a</li> </ul> <pre><code>gcc -static Script01.c -L. -lmylib\n</code></pre> <ul> <li>Fourth step: run the result, i.e. a.out, as usual</li> </ul> <pre><code>./a.out\n</code></pre>"},{"location":"Compilation%20Process/Basics/#dynamic-linking","title":"Dynamic Linking","text":"<ul> <li>First step: compile Script02.c into Script02.o, -fPIC compile to Position Independent Code Script02.o</li> </ul> <pre><code>gcc -c -fPIC Script02.c\n</code></pre> <ul> <li>Second step: create a shared (-shared) Dinamically Linked Library (.so) with Script02.o as a member of it</li> </ul> <pre><code>gcc -shared -o libmylib.so Script02.o\n</code></pre> <ul> <li>Third step: Static compile-link Script01.c with libmylib.a as a linked library</li> <li>'-L.' specifies the library path (current directory . or you can specify it)</li> <li>'-l' specifies the library as seen next</li> <li>'-lmylib' is specified without the prefex lib, as well as the suffix .a</li> </ul> <pre><code>gcc Script01.c -L. -lmylib\n</code></pre> <ul> <li>Third-2 step: exporting the LD_LIBRARY = ./</li> <li>If the library is not in the curent directory set LD_LIBRARY_PATH to point to the directory containing the library</li> </ul> <pre><code>export LD_LIBRARY_PATH = ./\n</code></pre> <ul> <li>Fourth step: run the result, i.e. a.out, as usual</li> </ul> <pre><code>./a.out\n</code></pre>"},{"location":"Shell/Arch/","title":"Arch linux","text":"<p>References:</p> <ul> <li>Gentoo AMD 64 handbook</li> <li>Archwiki</li> </ul> <p>The best guide to follow is the Archwiki, as it is always up to date. This guide, however, will give more explanations throughout the process, by spending more words for each step.</p>"},{"location":"Shell/Arch/#setting-the-keymap","title":"Setting the keymap","text":"<p>When in \"root@archiso\", list all of the available keymaps:</p> <pre><code>ls /usr/share/kbd/keymaps/**/*.map.gz\n</code></pre> <p>loadkeys: it-latin1</p>"},{"location":"Shell/Arch/#internet-through-the-smartphone-tethering","title":"Internet through the Smartphone tethering","text":"<ul> <li>Setting up the internet</li> </ul> <p>We enter the deamon called \"iwd\" which then appears as a prompt where we input commands</p> <pre><code>iwctl\n</code></pre> <p>This command prompts out the list of wi-fi devices through which we can connect to a given network</p> <pre><code>device list\n</code></pre> <p>Let's call the device that we're using \"wlan0\", SSID is the name of the chosen network we want to connect, it then asks for a passphrase. More details about this on this link.</p> <pre><code>station wlan0 scan\nstation wlan0 get-networks\n# SSID is the name of the Wi-Fi\nstation wlan0 connect SSID\n</code></pre>"},{"location":"Shell/Arch/#checking-network-connection","title":"Checking Network connection","text":"<p>After connecting, type \"exit\" while on the iwd daemon to quit the program, then, as root user, type the following to check out if the connection was successful.</p> <pre><code>ping google.com\n</code></pre>"},{"location":"Shell/Arch/#making-sure-our-system-clock-is-accurate","title":"Making sure our system clock is accurate","text":"<pre><code>timedatectl set-ntp true\n</code></pre> <pre><code>timedatectl set-timezone Europe/Rome\n</code></pre> <p>Verify it with</p> <pre><code>timedatectl status\n</code></pre>"},{"location":"Shell/Arch/#disk-partitioning-with-fdisk","title":"Disk partitioning with fdisk","text":"<p>/dev/sda is the name of the drive we want to partition, where it will be mounted the various parts of the system, among which \"/mnt\", where the OS will be mounted.</p> <pre><code>fdisk -l # listing all of our drives\nfdisk /dev/sda #the name of the Disk where I want to install Arch\n</code></pre> <p>Creating a new Label</p> <pre><code>g # to create a GPT partition table, for EFI\n</code></pre>"},{"location":"Shell/Arch/#using-fdisk-to-create-three-partitions","title":"Using fdisk to create three partitions","text":""},{"location":"Shell/Arch/#partitioning-the-efi-system-the-modern-bios-substitute","title":"Partitioning the EFI system (the modern BIOS substitute)","text":"<pre><code>n\n# input number \"1\"\n# press the enter key (default 2048)\n+550M # megabytes for the EFI partition # Don't input \"n\" again, there's a question .. answer \"yes\"\n</code></pre>"},{"location":"Shell/Arch/#swap-partition","title":"Swap partition","text":"<pre><code>n\n2\n# enter (default 2048)\n+2G # two gigabytes for the swap partition\n</code></pre>"},{"location":"Shell/Arch/#linux-file-system-partition","title":"Linux file system partition","text":"<pre><code>n\n3\n# enter (dafault 2048)\n# enter allocates the remaining storage for the linux file system\n</code></pre>"},{"location":"Shell/Arch/#if-any-mistakes-are-being-made","title":"If any mistakes are being made","text":"<p>Se sbaglio ad assegnare il tipo di partizione delle prime due, posso sempre premere t e il numero della partizione alla quale devo cambiare il tipo:</p> <p>esempio: t 1 L per listare i tipi di partizione disponibili 1 per EFI System e cambia da linux file system a EFI System</p> <p>t 2 L per listare i tipi di partizione disponibili 19 per Linux swap e cambia da linux file system a Linux swap</p> <p>Alla fine premi w per scrivere sul disco le nostre impostazioni</p>"},{"location":"Shell/Arch/#file-system","title":"File System","text":"<p>Ora dobbiamo creare i diversi tipi di File System rispettivamente per ogni partizione che abbiamo creato:</p> <p>Creating the file system Fat 32 in sda1</p> <pre><code>mkfs.fat -F32 /dev/sda1\n</code></pre> <p>Create the SWAP partition in sda2</p> <pre><code>mkswap /dev/sda2\n</code></pre> <p>Activate the SWAP partition</p> <pre><code>swapon /dev/sda2\n</code></pre> <p>Creating the File System in sda3</p> <pre><code>mkfs.ext4 /dev/sda3\n</code></pre> <p>Mount the file system</p> <pre><code>mount /dev/sda3 /mnt\n</code></pre> <p>Installing the base system with pacstrap</p> <pre><code>pacstrap /mnt base linux linux-firmware\n</code></pre>"},{"location":"Shell/Arch/#generating-system-tabular-file-fstab-which-gives-infos-on-our-partitioning","title":"Generating system tabular file fstab which gives infos on our partitioning:","text":"<pre><code>genfstab -U /mnt &gt;&gt; /mnt/etc/fstab\n</code></pre> <p>Ora diventiamo root della nostra installazione, ovvero passiamo dalla pendrive alla partizione /dev/sda3: arch-chroot /mnt</p> <p>Ora il prompt dovrebbe essere cambiato, perch\u00e9 siamo nel nostro sistema operativo di base nella nostra partizione /dev/sda3 dentro il nostro file system</p>"},{"location":"Shell/Arch/#locale","title":"Locale","text":"<p>Setting the time-zone</p> <pre><code>ln -sf /usr/share/zoneinfo/Europe/Rome /etc/localtime\n</code></pre> <p>If I had to list them all</p> <pre><code>ls /usr/share/zoneinfo\n</code></pre> <p>System clock settings:</p> <pre><code>hwclock --systohc\n</code></pre>"},{"location":"Shell/Arch/#install-neovim","title":"Install neovim","text":"<pre><code>pacman -Sy neovim\n</code></pre>"},{"location":"Shell/Arch/#install-iwd","title":"Install iwd","text":"<pre><code>pacman -Sy iwd\n</code></pre>"},{"location":"Shell/Arch/#setting-up-the-locale","title":"Setting up the Locale","text":"<pre><code>vim /etc/locale.gen\nen_US.UTF-8 UTF-8\n</code></pre> <p>Now activate the locale.gen </p> <pre><code>locale-gen\n</code></pre> <p>Creating a config file on /etc/hostname</p> <pre><code>vim /etc/hostname\n# I could write, for example:\nt440p\n</code></pre>"},{"location":"Shell/Arch/#modifichiamo-il-file-hosts","title":"Modifichiamo il file hosts","text":"<pre><code>vim /etc/hosts\n  ```\n\nAnd I write on it the following..\n\n```shell\n127.0.0.1 localhost\n::1 localhost\n127.0.1.1 t440p.localdomain t440p\n</code></pre>"},{"location":"Shell/Arch/#creating-the-users-with-their-relative-passwords","title":"Creating the Users with their relative passwords","text":"<p>The default user is the root user. To create other users Ora devo creare diversi utenti e una password, altrimenti ci sar\u00e0 solo 1 utente, ovvero il root Per la password root basta passwd senza nessun parametro da linea di comando: passwd 3394 Per l'utente: useradd -m angelo Creo password utente: passwd angelo 3394</p> <p>Checkpoint 21:20</p> <p>Su Unix ci sono vari gruppi ai quali gli utenti possono partecipare. usermod \u00e8 il comando in questione. Aggiungo l'utente angelo ai seguenti gruppi: usermod -aG wheel,audio,video,optical,storage angelo Edito il file sudoers dove sudo attribuisce i privilegi, e io voglio dare all'utente angelo il privilegio di usare sudo: visudo Tolgo il commento da:</p> <pre><code># %wheel ALL=(ALL) ALL // Da rivedere bene ..\n</code></pre>"},{"location":"Shell/Arch/#install-sudo","title":"Install sudo","text":"<pre><code>pacman -S sudo\n</code></pre>"},{"location":"Shell/Arch/#install-grub","title":"Install grub","text":"<pre><code>pacman -S grub\n</code></pre>"},{"location":"Shell/Arch/#installing-other-useful-packages","title":"Installing other useful packages","text":"<pre><code>pacman -S efibootmgr dosfstools os-prober mtools\n</code></pre>"},{"location":"Shell/Arch/#mounting-the-efi-partition","title":"Mounting the EFI partition","text":"<p>mkdir /boot/EFI mount /dev/sda1 /boot/EFI This doesn't work (don't know why): grub-install --target=x86_64-efi --bootloader-id=grub_uefi --recheck</p> <p>Heads up for those with MSI boards, apparently for some MSI bios versions it doesn't  recognize the standard grub installation path so it would boot to the bios, bypassing grub completely.  Luckily it's a simple fix you have to add --removable so the right command be  \"grub-install --target=x86_64-efi --removeable --bootloader-id=grub_uefi --recheck\".  Credit goes to Ryan in the comments of the Open  Source Home's tutorial of how to install arch that video is also here on Youtube. This works: grub-install --target=x86_64-efi --bootloader-id=GRUB --efi-directory=/boot/EFI --removable Creo il file delle configurazioni di grub: grub-mkconfig -o /boot/grub/grub.cfg</p> <p>Install iwd onto the machine before leaving the live installation process https://bbs.archlinux.org/viewtopic.php?id=187798</p> <p>Install network manager: pacman -S networkmanager vim xorg</p> <p>Enable networkmanager with systemd: systemctl enable NetworkManager systemctl enable iwd</p> <p>exit the chroot exit</p> <p>Unmount umount -l /mnt</p> <p>Ora ci sono due strade: 1) reboot se sei con un vero pc</p> <p>2) shutdown now se sei in una VM vai su storage clicca sulla iso e rimuove lo storage e restart</p> <p>Linux Drive and Partition Config (dd, fdisk, resize2fs, lsblk, tune2fs and more) Sed, Awk, Grep, Cat, gpg, ssh, git, make, zsh</p>"},{"location":"Shell/Cloud/","title":"Connecting to a GPU cluster: a walkthrough","text":"<p>Connecting to a GPU cluster to perform calculation is becoming an everyday task we all have to measure ourselves with. It is important to understand how to \"ssh into a remote server\" to perform computations, and, in the context of Deep Learning, we are expected to run the experiments using CUDA or python3, perhaps with the aid of an interface that a jupyter notebook, other than the terminal.</p>"},{"location":"Shell/Cloud/#the-key-that-well-use-to-connect-to-the-server","title":"The key that we'll use to connect to the server","text":"<p>When we want to connect to a remote supercomputer we are being issued a key. This key is a file with the extension \".pem\". Let's suppose we download, from the website of the cloud provider, this file onto the ~/Downloads directory. We have the following workflow:</p> <pre><code>chmod 600 ~/Downloads/test-key-gpu.pem\n</code></pre> <p>which does the following:</p> <ul> <li><code>chmod 600</code>: This changes the file permissions for <code>test-key-gpu.pem</code>. Specifically, it sets the file to be readable and writable by the owner (you) and removes all permissions for anyone else. The numeric mode <code>600</code> is broken down as follows:</li> <li>The first digit (<code>6</code>) means the owner can read and write the file (<code>4 + 2 = 6</code>).</li> <li> <p>The other two digits (<code>0 0</code>) mean that no other users (group or others) have any permissions.</p> </li> <li> <p><code>~/Downloads/test-key-gpu.pem</code>: This is the path to the private SSH key file (used to authenticate your SSH connection) that you've likely downloaded to access the cloud GPU instance. The <code>~</code> represents your home directory, so this file is stored in your <code>Downloads</code> folder.</p> </li> </ul> <p>(Optional) You can copy the private key to your <code>.ssh</code> directory with the following command:</p> <pre><code>cp ~/Downloads/test-key-gpu.pem ~/.ssh\n</code></pre>"},{"location":"Shell/Cloud/#connecting-to-the-remote-cluster","title":"Connecting to the remote cluster","text":"<p>The command to do so is: <code>ssh -i ~/Downloads/test-key-gpu.pem ubuntu@96.76.203.50</code></p> <ul> <li> <p><code>-i ~/Downloads/test-key-gpu.pem</code>: This flag specifies the identity file (private key) for SSH to use for authentication. In this case, <code>~/Downloads/test-key-gpu.pem</code> is the file path to the private key, stored in your <code>Downloads</code> folder.</p> </li> <li> <p><code>ubuntu@96.76.203.50</code>:</p> </li> <li><code>ubuntu</code>: The username to log into the remote server. It is common for cloud instances running Ubuntu to default to the <code>ubuntu</code> user.</li> <li><code>96.76.203.50</code>: This is the IP address of the remote server (likely your cloud GPU instance).</li> </ul>"},{"location":"Shell/Cloud/#what-happens-next","title":"What happens next?","text":"<p>This command connects you to the remote cloud GPU instance using SSH, authenticating with the private key specified, and logs you in as the <code>ubuntu</code> user. </p> <p>Once connected, the terminal prompt will change, indicating you are now controlling the remote server. At this point, you might want to use <code>tmux</code> (for terminal multiplexing) and <code>nvim</code> (for code editing). For example, you could split your <code>tmux</code> session into three panes\u2014one to monitor GPU usage with <code>nvidia-smi</code>, another for system monitoring with <code>htop</code>, and a third for running Python.</p>"},{"location":"Shell/Cloud/#copying-files-between-local-machine-and-cloud-instance","title":"Copying Files Between Local Machine and Cloud Instance:","text":""},{"location":"Shell/Cloud/#copying-from-remote-to-local","title":"Copying from Remote to Local:","text":"<p>To copy a file (<code>foo.py</code>) from the remote server to your local machine, use:</p> <pre><code>scp -i ~/Downloads/test-key-gpu.pem ubuntu@96.76.203.50:~/foo.py .\n</code></pre> <ul> <li><code>scp</code>: This command securely transfers files over SSH.</li> <li><code>-i ~/Downloads/test-key-gpu.pem</code>: Specifies the identity file (private key) for authentication.</li> <li><code>ubuntu@96.76.203.50:~/foo.py</code>: The remote user (<code>ubuntu</code>), the server (<code>96.76.203.50</code>), and the file path (<code>~/foo.py</code>) you want to copy from.</li> <li><code>.</code> (dot): This specifies the current directory on your local machine as the destination.</li> </ul>"},{"location":"Shell/Cloud/#copying-from-local-to-remote","title":"Copying from Local to Remote:","text":"<p>To upload a file (<code>random.txt</code>) from your local machine to the remote instance:</p> <pre><code>scp -i ~/Downloads/test-key-gpu.pem random.txt ubuntu@96.76.203.50:~/\n</code></pre> <p>This copies the file <code>random.txt</code> to the home directory of the <code>ubuntu</code> user on the remote instance.</p>"},{"location":"Shell/Cloud/#monitoring-python-processes","title":"Monitoring Python Processes:","text":"<p>It is important to monitor python processes in the remote machine. To check for running Python processes on the remote server, you can use:</p> <pre><code>ps ax | grep python3\n</code></pre> <p>This will show any running instances of <code>python3</code>. To terminate a process, use:</p> <pre><code>kill -9 &lt;process_id&gt;\n</code></pre> <p>Replace <code>&lt;process_id&gt;</code> with the actual ID of the Python process you want to kill. Note that  is discoverable through htop, or some other top-like program."},{"location":"Shell/Cloud/#running-a-jupyter-notebook-on-the-cloud","title":"Running a Jupyter Notebook on the Cloud:","text":"<p>You can set up a Python virtual environment and run a Jupyter Notebook on your cloud GPU instance:</p> <ol> <li> <p>Create a virtual environment:    <code>bash    python3 -m venv jpr</code></p> </li> <li> <p>Install Jupyter and TensorFlow (or PyTorch):    <code>bash    pip install jupyter    pip install tensorflow-gpu  # For TensorFlow    # or    pip install torch  # For PyTorch</code></p> </li> <li> <p>If needed, uninstall packages:    <code>bash    pip uninstall tensorflow-gpu</code></p> </li> <li> <p>Check your CUDA version:    <code>bash    nvcc --version</code></p> </li> </ol> <p>If your CUDA version is 9.0, you may need to install a specific version of TensorFlow:    <code>bash    pip install tensorflow-gpu==1.12.0</code></p> <ol> <li>Run Jupyter Notebook, setting the IP to <code>0.0.0.0</code> so it can be accessed over the network:    <code>bash    jupyter notebook --ip=0.0.0.0</code></li> </ol>"},{"location":"Shell/Cloud/#terminating-the-instance","title":"Terminating the Instance:","text":"<p>Terminating a cloud instance will result in a complete loss of all data on the instance. This is typically done through the cloud provider\u2019s web interface. However, you should terminate the active SSH connection from your local machine by simply typing:</p> <pre><code>exit\n</code></pre> <p>or by closing the terminal.</p>"},{"location":"Shell/Starter/","title":"Starting Shell Programming","text":"<p>Learning how to use sed, awk, grep, cat, fdisk and more</p>"},{"location":"Shell/Starter/#tools-needed","title":"Tools needed","text":"<ul> <li>Shell: zsh, bash, ash, dash</li> <li>Any TUI text editor (Vim, Emacs, Nano ..)</li> <li>Any terminal emulator</li> </ul>"},{"location":"Shell/Starter/#adding-to-path-any-folder-of-executable-scripts","title":"Adding to $PATH any folder of executable scripts","text":"<p>Open your \".zshrc\" or \".bashrc\". Ideally these two files are located in your ~/ folder. To add the folder named \"bin\" to the $PATH variable, just add the following to your configuration file</p> <pre><code>export PATH=\"$PATH:/home/username/bin\"\n</code></pre> <p>Now you can write your scripts in python, shell or other languages, making them executable and add the folder where these scripts are located to your $PATH environment variable to use them everywhere while browsing your filesystem with the shell</p> <p>If you have a script that launches a specific application, you can use symlinking and adding to $PATH to launch that application from anywhere in your file system</p> <pre><code>ln -s /home/username/programs/java/eclipse/eclipse /home/username/bin\n</code></pre>"},{"location":"Shell/Starter/#getting-the-size-of-a-directory-on-the-command-line","title":"Getting the size of a directory on the command line","text":"<pre><code>du -s, --summarize\n        # display only a total for each argument\n\ndu -h, --human-readable\n        # print sizes in human readable format (e.g., 1K 234M 2G)\n\ndu -hs\n</code></pre> <p>Adding a directory to the PATH environment variable in Linux is a useful way to ensure that the executables in that directory can be run from any location in the command line without specifying the full path. Here\u2019s how to add a directory to your PATH in a few steps:</p>"},{"location":"Shell/Starter/#temporary-addition","title":"Temporary Addition","text":"<p>If you want to add a directory to the PATH temporarily, meaning it will only last for the duration of the session or terminal window, you can use the following command in the terminal:</p> <pre><code>export PATH=$PATH:/path/to/directory\n</code></pre> <p>Replace <code>/path/to/directory</code> with the actual path of the directory you want to add. This change will last until the terminal is closed.</p>"},{"location":"Shell/Starter/#permanent-addition","title":"Permanent Addition","text":"<p>To make the addition permanent, you will need to add the export command to a startup file like <code>.bashrc</code>, <code>.bash_profile</code>, or <code>.profile</code>, depending on the shell and setup you are using.</p> <ol> <li>Open your terminal.</li> <li>Edit the startup file:</li> <li>If you are using Bash, you can add the directory to your PATH in your <code>.bashrc</code> or <code>.bash_profile</code> file. Open the file with a text editor, such as nano:      <code>bash      nano ~/.bashrc</code></li> <li> <p>For other shells, like Zsh, you might edit <code>.zshrc</code>.</p> </li> <li> <p>Add the export command to the end of the file:    <code>bash    export PATH=$PATH:/path/to/directory</code>    Again, replace <code>/path/to/directory</code> with your specific directory.</p> </li> <li> <p>Save and close the file. For nano, press <code>Ctrl + X</code>, then <code>Y</code> to confirm, and <code>Enter</code> to save.</p> </li> <li> <p>Source the file to apply the changes immediately without needing to restart your terminal:    <code>bash    source ~/.bashrc</code>    Replace <code>.bashrc</code> with the name of the file you edited, if different.</p> </li> </ol>"},{"location":"Shell/Starter/#verify-the-change","title":"Verify the Change","text":"<p>After adding the directory to your PATH, you can verify that it was added successfully by typing:</p> <pre><code>echo $PATH\n</code></pre> <p>This command will display the contents of your PATH variable, and you should see your directory listed there.</p> <p>Adding directories to the PATH is a common practice for simplifying command executions and script runs, especially for custom scripts or software installed in non-standard locations.</p>"},{"location":"Shell/Tweaks/","title":"Tweaking the System","text":""},{"location":"Shell/Tweaks/#chaning-resolution-of-the-screen-with-xrandr","title":"Chaning resolution of the screen with xrandr","text":"<p>Listing all possible resolution settings</p> <pre><code>xrandr\n</code></pre> <p>Listing the names of the active monitors</p> <pre><code>xrandr --listactivemonitors\n</code></pre> <p>Give an active monitor named \"eDP-1\", this sets the resolution at 1024x768</p> <pre><code>xrandr --output eDP-1 --mode 1024x768\n</code></pre>"},{"location":"Shell/Tweaks/#symlinking","title":"Symlinking","text":""},{"location":"Shell/Tweaks/#usefulness-of-symbolic-linking","title":"Usefulness of symbolic linking","text":"<p>After installing telegram on my machine, in some location, I could just create a symbolic link to allow dmenu to find the program among the /usr/bin/ (and possibly even /usr/local/bin/) executables.  dmenu actively finds its own executables from that directory.  The implications are that since that directory is also part of the $PATH environment variable, at least for ZSH and Bash, we can invoke these executables also from the commandline itself, no matter the path we're in while navigating the file system with out shell.</p> <pre><code>sudo ln -s /home/angelo/AppImages/Telegram/Telegram /usr/bin/telegram\n</code></pre>"}]}